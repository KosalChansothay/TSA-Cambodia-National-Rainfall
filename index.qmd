---
title: "Cambodia Provincial Rainfall"
subtitle: "Time Series Analysis & Forecasting | Pursat Province | Dr. SIM Tepmony"
institute: "Institute of Technology of Cambodia | Dept. AMS"
author: "Group 01 | CHEA Piseth | KHUN Sithanut | <span style='color:#048373;'>KOSAL Chansothay</span> | HENG Sopanha"
date: "23 January 2026"
format:
  revealjs:
    theme: [default, custom.scss]
    slide-number: true
    chalkboard: true
    preview-links: auto
    logo: "AMS.png"
    footer: "Time Series Analysis | Dr. SIM Tepmony | January 2026"
    transition: slide
    background-transition: fade
    highlight-style: github
    code-fold: true
    code-tools: true
    code-line-numbers: false
    scrollable: true
    smaller: false
    fig-align: center
execute:
  echo: true
  warning: false
  message: false
---

## Course Information {.center}

::: {.columns}
::: {.column width="50%"}
### Course Details
- **Course:** Time Series Analysis
- **Group:** 01
- **Instructor:** Dr. SIM Tepmony
- **Date:** January 2026
:::

::: {.column width="50%"}
### Project Overview
- **Topic:** Pursat Province Rainfall Analysis
- **Data Source:** Humanitarian Data Exchange (HDX)
- **Period:** 1981 – 2026
- **Method:** ARIMA/SARIMA Modeling
:::
:::

---

## Table of Contents

::: {.incremental}
1. **Introduction** – Research motivation and objectives
2. **Data Loading** – Acquiring rainfall data from HDX
3. **Data Preprocessing** – Building provincial monthly series
4. **Exploratory Data Analysis** – Patterns and statistics
5. **Time Series Decomposition** – Trend, seasonal, residual
6. **Stationarity Testing** – ADF test and differencing
7. **ACF/PACF Analysis** – Model identification
8. **Train-Test Split** – No data leakage approach
9. **Model Development** – AR, MA, ARMA, ARIMA, SARIMA
10. **Model Evaluation** – Out-of-sample performance comparison
11. **Residual Diagnostics** – Model validation
12. **Forecasting** – 24-month rainfall forecast
13. **Conclusion** – Key findings and recommendations
:::

---

## Introduction

### Research Motivation

::: {.columns}
::: {.column width="60%"}
- Cambodia's economy is **heavily dependent on agriculture**
- **Pursat Province** is a major rice-producing region
- Rainfall patterns directly impact:
  - Rice cultivation and crop yields
  - Water resource management
  - Flood and drought preparedness
- Understanding rainfall trends enables **better planning**
:::

::: {.column width="40%"}
### Objectives
::: {.callout-tip}
1. Build a provincial monthly rainfall time series
2. Identify seasonal patterns and trends
3. Develop accurate forecasting models using rolling evaluation
4. Produce 24-month rainfall forecasts
:::
:::
:::

---

## Setup and Libraries

```{python}
#| code-fold: true
#| code-summary: "Show setup code"

import warnings
warnings.filterwarnings("ignore")

# Data manipulation
import numpy as np
import pandas as pd

# Visualization
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

# Time series tools
from statsmodels.tsa.stattools import adfuller, acf, pacf
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.tsa.seasonal import seasonal_decompose
from statsmodels.tsa.arima.model import ARIMA
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.stats.diagnostic import acorr_ljungbox
from scipy import stats

# Metrics
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score

np.random.seed(42)
```

::: {.callout-note}
**Libraries Used:**

::: {.callout-note}
**Libraries Used:** pandas, numpy, plotly, statsmodels, scikit-learn, scipy
:::

<p align="center">
  <img src="https://pandas.pydata.org/static/img/pandas.svg" alt="pandas" width="100"/>
  <img src="https://numpy.org/images/logo.svg" alt="numpy" width="100"/>
  <img src="https://upload.wikimedia.org/wikipedia/commons/thumb/8/8a/Plotly-logo.png/960px-Plotly-logo.png?20220718173326" alt="plotly" width="120"/>
  <img src="https://www.statsmodels.org/stable/_images/statsmodels-logo-v2-horizontal.svg" alt="statsmodels" width="160"/>
  <img src="https://scikit-learn.org/stable/_static/scikit-learn-logo-small.png" alt="scikit-learn" width="120"/>
</p>

:::

---

## Data Loading

### Humanitarian Data Exchange (HDX) Dataset

```{python}
#| code-fold: true
#| code-summary: "Show data loading code"

url = "https://data.humdata.org/dataset/8fa90d2b-a88e-414d-84a1-50d6bc773542/resource/67c4f3d6-f600-4699-9a67-0de20d6a1b0b/download/khm-rainfall-subnat-full.csv"

print("Loading Cambodia rainfall dataset...")
df_raw = pd.read_csv(url)
df_raw["date"] = pd.to_datetime(df_raw["date"])

print(f"✓ Dataset loaded successfully!")
print(f"  Shape: {df_raw.shape[0]:,} rows × {df_raw.shape[1]} columns")
print(f"  Date range: {df_raw['date'].min().strftime('%Y-%m-%d')} to {df_raw['date'].max().strftime('%Y-%m-%d')}")
```

::: {.columns}
::: {.column width="50%"}
### Data Source
- **Provider:** OCHA HDX Platform
- **Coverage:** All Cambodian provinces
- **Frequency:** Dekadal (10-day periods)
:::

::: {.column width="50%"}
### Key Variables
- `date` – Observation date
- `rfh` – Rainfall (mm)
- `adm_level` – Administrative level
- `PCODE` – Province code
:::
:::

---

## Raw Data Overview

```{python}
#| code-fold: true
#| code-summary: "Show data preview"

# Display first few rows
print("First 5 rows of raw data:")
df_raw.head(5)
```

```{python}
#| code-fold: true
#| code-summary: "Show column info"

print("\nColumn Information:")
print(df_raw.dtypes)
print(f"\nUnique administrative levels: {df_raw['adm_level'].unique()}")
print(f"Number of provinces (adm_level=1): {df_raw[df_raw['adm_level']==1]['PCODE'].nunique()}")
```

```{python}
#| code-fold: true
#| code-summary: "Show available provinces"

# Show available provinces
df_province = df_raw[df_raw["adm_level"] == 1].copy()
province_counts = df_province.groupby("PCODE").size().sort_values(ascending=False)
print("Available provinces and record counts:")
print(province_counts.head(10))
```

---

## Data Preprocessing

### Selecting Pursat Province

```{python}
#| code-fold: true
#| code-summary: "Show preprocessing code"

# Filter to provincial level (adm_level == 1)
df_province = df_raw[df_raw["adm_level"] == 1].copy()

# Select Pursat province (province with most complete data)
province_counts = df_province.groupby("PCODE").size()
selected_province = province_counts.idxmax()

print(f"Selected province: {selected_province}")
print(f"Records: {province_counts[selected_province]}")

# Filter for selected province
df_selected = df_province[df_province["PCODE"] == selected_province].copy()
df_selected = df_selected.sort_values("date").reset_index(drop=True)
df_selected = df_selected[["date", "rfh"]].copy()
df_selected.columns = ["date", "rainfall"]

print(f"\nData range: {df_selected['date'].min()} to {df_selected['date'].max()}")
```

```{python}
#| code-fold: true
#| code-summary: "Show missing value handling"

# Handle missing values
missing_before = df_selected["rainfall"].isna().sum()
df_selected["rainfall"] = df_selected["rainfall"].ffill().bfill()
missing_after = df_selected["rainfall"].isna().sum()

print(f"Missing values: {missing_before} → {missing_after} (after imputation)")
```

$$
\tilde{x}_t =
\begin{cases}
x_t, & \text{if } x_t \text{ is observed}, \\[1pt]
x_{t^-}, & \text{if } x_t \text{ is missing and a previous value exists (forward fill)}, \\[1pt]
x_{t^+}, & \text{if } x_t \text{ is missing and only a later value exists (backward fill)}.
\end{cases}
$$

---

## Monthly Aggregation

### Building Provincial Monthly Series

```{python}
#| code-fold: true
#| code-summary: "Show aggregation code"

# Create year-month period
df_selected["year_month"] = df_selected["date"].dt.to_period("M")

# Aggregate to monthly totals for Pursat province
df_monthly = (
    df_selected.groupby("year_month")
    .agg(rainfall=("rainfall", "sum"))
    .reset_index()
)
df_monthly["date"] = df_monthly["year_month"].dt.to_timestamp()
df_monthly = df_monthly[["date", "rainfall"]].copy()

print(f"✓ Provincial monthly series created")
print(f"  Total months: {len(df_monthly)}")
print(f"  Range: {df_monthly['date'].min().strftime('%Y-%m')} to {df_monthly['date'].max().strftime('%Y-%m')}")
```

::: {.callout-note}
**Monthly Aggregation Formula:**
$$Y_m = \sum_{d \in m} y_d$$

where $Y_m$ is total rainfall in month $m$, and $y_d$ is rainfall on day/dekad $d$.
:::

---

## Preprocessing Summary

::: {.columns}
::: {.column width="50%"}
### Steps Performed
1. **Filtered** provincial-level records (`adm_level == 1`)
2. **Selected** Pursat province (most complete data)
3. **Imputed** missing rainfall values (forward/backward fill)
4. **Aggregated** dekadal data to monthly totals
:::

::: {.column width="50%"}
### Result
::: {.callout-tip}
**Pursat Provincial Monthly Rainfall Series**

- **Observations:** ~540 months
- **Period:** 1981 – 2026
- **Frequency:** Monthly (MS)
- **Unit:** Total rainfall (mm)
:::
:::
:::

```{python}
#| echo: false

# Create time series object
ts_data = df_monthly.set_index("date")["rainfall"].asfreq("MS")
ts = ts_data
```

---

## Exploratory Data Analysis

### Pursat Provincial Monthly Rainfall Time Series

```{python}
#| code-fold: true
#| code-summary: "Show visualization code"

fig = px.line(
    df_monthly, 
    x="date", 
    y="rainfall",
    title="Pursat Province Monthly Rainfall (1981–2026)",
    labels={"date": "Date", "rainfall": "Rainfall (mm)"}
)
fig.update_traces(line_color="#3498db", line_width=1.5)
fig.update_layout(
    hovermode="x unified",
    xaxis_title="Date",
    yaxis_title="Rainfall (mm)",
    template="plotly_white",
    height=450
)
fig.show()
```

::: {.callout-note}
**Observation:** Clear annual cyclical pattern with peaks during monsoon season (May–October) and low values during dry season (November–April).
:::

---

## Descriptive Statistics

```{python}
#| code-fold: true
#| code-summary: "Show statistics code"

stats = {
    "Count": len(ts),
    "Mean (mm)": ts.mean(),
    "Median (mm)": ts.median(),
    "Std Dev": ts.std(),
    "Min (mm)": ts.min(),
    "Max (mm)": ts.max(),
    "Range (mm)": ts.max() - ts.min(),
    "Q1 (25%)": ts.quantile(0.25),
    "Q3 (75%)": ts.quantile(0.75),
    "IQR": ts.quantile(0.75) - ts.quantile(0.25),
    "CV (%)": ts.std() / ts.mean() * 100,
    "Skewness": ts.skew(),
    "Kurtosis": ts.kurtosis(),
}

stats_df = pd.DataFrame(list(stats.items()), columns=["Statistic", "Value"])
stats_df["Value"] = stats_df["Value"].round(2)
stats_df
```

::: {.callout-tip}
**High CV (>50%)** indicates strong wet/dry season variability – typical for tropical monsoon climates.
:::

---

## Monthly Rainfall Distribution

```{python}
#| code-fold: true
#| code-summary: "Show distribution plot code"

# Add month for grouping
df_monthly["month"] = df_monthly["date"].dt.month
df_monthly["month_name"] = df_monthly["date"].dt.strftime("%b")

# Monthly boxplot
fig = px.box(
    df_monthly, 
    x="month", 
    y="rainfall",
    title="Pursat Province: Monthly Rainfall Distribution",
    labels={"month": "Month", "rainfall": "Rainfall (mm)"}
)
fig.update_layout(
    xaxis=dict(
        tickmode="array",
        tickvals=list(range(1, 13)),
        ticktext=["Jan", "Feb", "Mar", "Apr", "May", "Jun", 
                  "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"]
    ),
    template="plotly_white",
    height=450
)
fig.show()
```

::: {.callout-note}
**Peak rainfall months:** May–October (monsoon season) | **Dry months:** November–April
:::

---

## Seasonal Decomposition

### Additive Decomposition Model

$$y_t = T_t + S_t + R_t$$

where:
- $T_t$ = Trend component
- $S_t$ = Seasonal component  
- $R_t$ = Residual (irregular) component

```{python}
#| code-fold: true
#| code-summary: "Show decomposition code"

# Perform seasonal decomposition
decomp = seasonal_decompose(ts, model="additive", period=12)

# Create subplots using plotly
fig = make_subplots(
    rows=4, cols=1,
    subplot_titles=("Observed", "Trend", "Seasonal", "Residual"),
    vertical_spacing=0.08
)

# Observed
fig.add_trace(go.Scatter(x=ts.index, y=ts.values, mode="lines", 
                         name="Observed", line=dict(color="#3498db")), row=1, col=1)

# Trend
fig.add_trace(go.Scatter(x=decomp.trend.index, y=decomp.trend.values, mode="lines",
                         name="Trend", line=dict(color="#e74c3c")), row=2, col=1)

# Seasonal
fig.add_trace(go.Scatter(x=decomp.seasonal.index, y=decomp.seasonal.values, mode="lines",
                         name="Seasonal", line=dict(color="#2ecc71")), row=3, col=1)

# Residual
fig.add_trace(go.Scatter(x=decomp.resid.index, y=decomp.resid.values, mode="lines",
                         name="Residual", line=dict(color="#9b59b6")), row=4, col=1)

fig.update_layout(height=700, showlegend=False, template="plotly_white",
                  title_text="Additive Seasonal Decomposition (Period = 12 months)")
fig.show()
```

---

## Decomposition Interpretation

::: {.columns}
::: {.column width="50%"}
### Components Identified
- **Trend:** Slight long-term variations, no strong upward/downward trend
- **Seasonal:** Strong 12-month cyclical pattern (monsoon cycle)
- **Residual:** Random fluctuations around zero
:::

::: {.column width="50%"}
### Key Insights
::: {.callout-tip}
1. **Seasonality dominates** the series
2. Monsoon cycle is **consistent** across decades
3. **Additive model** is appropriate (seasonal amplitude relatively constant)
4. Need to account for seasonality in forecasting
:::
:::
:::

---

## Stationarity Testing

### Augmented Dickey-Fuller (ADF) Test

**Hypothesis:**
- $H_0$: Series has a unit root (non-stationary)
- $H_1$: Series is stationary

**Decision Rule:** If p-value < 0.05, reject $H_0$ (series is stationary)

```{python}
#| code-fold: true
#| code-summary: "Show ADF test code"

def adf_test(x, name="Series"):
    result = adfuller(x.dropna(), autolag="AIC")
    adf_results = {
        "Test": name,
        "ADF Statistic": round(result[0], 4),
        "p-value": result[1],
        "Lags Used": result[2],
        "Observations": result[3],
        "Critical 1%": round(result[4]["1%"], 4),
        "Critical 5%": round(result[4]["5%"], 4),
        "Critical 10%": round(result[4]["10%"], 4),
        "Stationary": "Yes ✓" if result[1] < 0.05 else "No ✗"
    }
    return adf_results

# Test original series
adf_original = adf_test(ts, "Original Series")

# Seasonal differencing (lag 12)
ts_seasonal_diff = ts.diff(12).dropna()
adf_diff = adf_test(ts_seasonal_diff, "Seasonally Differenced (D=1, s=12)")

# Display results
adf_df = pd.DataFrame([adf_original, adf_diff])
adf_df[["Test", "ADF Statistic", "p-value", "Stationary"]]
```

::: {.callout-important}
**Result:** The original series is stationary (ADF p < 0.05). After seasonal differencing at lag 12, the series is also stationary and suitable for SARIMA modeling.
:::

---

## Seasonal Differencing

### Mathematical Background

$$\nabla_s y_t = y_t - y_{t-s}$$

where $s = 12$ (seasonal period). This removes seasonal patterns and helps achieve stationarity.

```{python}
#| code-fold: true
#| code-summary: "Show seasonal differencing plot"

fig = go.Figure()

fig.add_trace(go.Scatter(
    x=ts_seasonal_diff.index, 
    y=ts_seasonal_diff.values, 
    mode="lines",
    name="Seasonally Differenced",
    line=dict(color="#2ecc71", width=1.5)
))

fig.add_hline(y=0, line_dash="dash", line_color="red", line_width=1)

fig.update_layout(
    title="Seasonally Differenced Series (lag=12)",
    xaxis_title="Date",
    yaxis_title="Differenced Rainfall (mm)",
    template="plotly_white",
    height=400
)
fig.show()
```

---

## ACF and PACF Analysis

### Model Identification

**Autocorrelation Function (ACF):**
$$\rho(k) = \frac{\text{Cov}(y_t, y_{t-k})}{\text{Var}(y_t)}$$

**Model Selection Guidelines:**
- **AR(p):** PACF cuts off after lag $p$, ACF decays
- **MA(q):** ACF cuts off after lag $q$, PACF decays
- **ARMA(p,q):** Both ACF and PACF decay

```{python}
#| code-fold: true
#| code-summary: "Show ACF/PACF code"
import plotly.graph_objects as go
from plotly.subplots import make_subplots
from statsmodels.tsa.stattools import acf, pacf
import numpy as np

# Calculate seasonal difference
ts_seasonal_diff = ts.diff(12)

# Calculate ACF and PACF values
acf_original = acf(ts.dropna(), nlags=40)
pacf_original = pacf(ts.dropna(), nlags=40)
acf_seasonal = acf(ts_seasonal_diff.dropna(), nlags=40)
pacf_seasonal = pacf(ts_seasonal_diff.dropna(), nlags=40)

# Calculate confidence intervals (95%)
n_original = len(ts.dropna())
n_seasonal = len(ts_seasonal_diff.dropna())
ci_original = 1.96 / np.sqrt(n_original)
ci_seasonal = 1.96 / np.sqrt(n_seasonal)

# Create subplots
fig = make_subplots(
    rows=2, cols=2,
    subplot_titles=(
        "ACF - Original Series",
        "PACF - Original Series",
        "ACF - Seasonally Differenced (lag=12)",
        "PACF - Seasonally Differenced (lag=12)"
    )
)

# Helper function to add ACF/PACF plot
def add_correlogram(fig, values, ci, row, col):
    lags = np.arange(len(values))
    
    # Add vertical lines
    for i, val in enumerate(values):
        fig.add_trace(
            go.Scatter(
                x=[i, i],
                y=[0, val],
                mode='lines',
                line=dict(color='steelblue', width=2),
                showlegend=False,
                hovertemplate=f'Lag: {i}<br>Value: {val:.3f}<extra></extra>'
            ),
            row=row, col=col
        )
    
    # Add confidence interval bands
    fig.add_trace(
        go.Scatter(
            x=lags,
            y=[ci] * len(lags),
            mode='lines',
            line=dict(color='rgba(255, 0, 0, 0.3)', dash='dash'),
            showlegend=False,
            hoverinfo='skip'
        ),
        row=row, col=col
    )
    
    fig.add_trace(
        go.Scatter(
            x=lags,
            y=[-ci] * len(lags),
            mode='lines',
            line=dict(color='rgba(255, 0, 0, 0.3)', dash='dash'),
            showlegend=False,
            hoverinfo='skip'
        ),
        row=row, col=col
    )
    
    # Add zero line
    fig.add_trace(
        go.Scatter(
            x=lags,
            y=[0] * len(lags),
            mode='lines',
            line=dict(color='black', width=1),
            showlegend=False,
            hoverinfo='skip'
        ),
        row=row, col=col
    )

# Add all plots
add_correlogram(fig, acf_original, ci_original, 1, 1)
add_correlogram(fig, pacf_original, ci_original, 1, 2)
add_correlogram(fig, acf_seasonal, ci_seasonal, 2, 1)
add_correlogram(fig, pacf_seasonal, ci_seasonal, 2, 2)

# Update layout
fig.update_xaxes(title_text="Lag", row=1, col=1)
fig.update_xaxes(title_text="Lag", row=1, col=2)
fig.update_xaxes(title_text="Lag", row=2, col=1)
fig.update_xaxes(title_text="Lag", row=2, col=2)

fig.update_yaxes(title_text="ACF", row=1, col=1)
fig.update_yaxes(title_text="PACF", row=1, col=2)
fig.update_yaxes(title_text="ACF", row=2, col=1)
fig.update_yaxes(title_text="PACF", row=2, col=2)

fig.update_layout(
    height=800,
    width=1200,
    title_text="ACF and PACF Analysis",
    showlegend=False
)

fig.show()
```

---

## ACF/PACF Interpretation

::: {.columns}
::: {.column width="50%"}
### Observations
- **ACF:** Significant spikes at lags 12, 24 (yearly seasonality)
- **PACF:** Cuts off after lag 1
- Clear **seasonal component** at period 12
:::

::: {.column width="50%"}
### Model Selection Guidance
::: {.callout-tip}
Based on ACF/PACF patterns:

- Use **D = 1** (seasonal differencing)
- Use **s = 12** (yearly seasonality)
- Try small orders: **p, q ∈ {0, 1}**
- Try seasonal orders: **P, Q ∈ {1}**
:::
:::
:::

---

## Train-Test Split

### No Data Leakage Approach

To prevent **data leakage**, we split the data temporally:
- **Train set:** Earlier observations (for model fitting)
- **Test set:** Last 60 months (~5 years) for out-of-sample evaluation

```{python}
#| code-fold: true
#| code-summary: "Show split code"

# Reserve last 60 months (5 years) for testing
test_horizon = 60
train = ts.iloc[:-test_horizon]
test = ts.iloc[-test_horizon:]

print(f"Training set: {train.index.min().strftime('%Y-%m')} to {train.index.max().strftime('%Y-%m')} ({len(train)} months)")
print(f"Test set:     {test.index.min().strftime('%Y-%m')} to {test.index.max().strftime('%Y-%m')} ({len(test)} months)")
```

```{python}
#| code-fold: true
#| code-summary: "Show split visualization"

import plotly.graph_objects as go

# Convert index to datetime if needed (safe guard)
train.index = train.index.to_timestamp() if hasattr(train.index, "to_timestamp") else train.index
test.index  = test.index.to_timestamp() if hasattr(test.index, "to_timestamp") else test.index

# Get split date safely
split_date = test.index[0].to_pydatetime()

fig = go.Figure()

# Training set
fig.add_trace(
    go.Scatter(
        x=train.index,
        y=train.values,
        mode="lines",
        name="Training Set",
        line=dict(color="#3498db")
    )
)

# Test set
fig.add_trace(
    go.Scatter(
        x=test.index,
        y=test.values,
        mode="lines",
        name="Test Set",
        line=dict(color="#e74c3c")
    )
)

# Vertical split line (NO annotation here)
fig.add_vline(
    x=split_date,
    line_dash="dash",
    line_color="black",
    line_width=2
)

# Manual annotation (safe)
fig.add_annotation(
    x=split_date,
    y=1,
    yref="paper",
    text="Train / Test Split",
    showarrow=False,
    font=dict(size=12, color="black"),
    xanchor="left",
    yanchor="bottom"
)

# Layout
fig.update_layout(
    title="Train–Test Split (Last 5 Years as Test)",
    xaxis_title="Date",
    yaxis_title="Rainfall (mm)",
    template="plotly_white",
    height=400,
    legend=dict(
        yanchor="top",
        y=0.99,
        xanchor="left",
        x=0.01
    )
)

fig.show()
```

---

## Model Development

### Rolling One-Step-Ahead Forecast Evaluation

We use **rolling forecasts** for true out-of-sample evaluation:
1. Fit model on training data
2. Forecast 1 step ahead
3. Add actual observation to training set
4. Repeat for entire test period

```{python}
#| code-fold: true
#| code-summary: "Show rolling forecast function"

def rolling_forecast_evaluation(series, order, seasonal_order=None, model_name="Model"):
    """
    Perform rolling one-step-ahead forecast on test set.
    """
    train_idx = series.index[:-test_horizon]
    test_idx = series.index[-test_horizon:]
    
    y_train = series.loc[train_idx]
    y_test = series.loc[test_idx]
    
    history = y_train.copy()
    predictions = []
    
    for t in range(len(y_test)):
        try:
            if seasonal_order is None:
                model = ARIMA(history, order=order)
            else:
                model = SARIMAX(history, order=order, seasonal_order=seasonal_order,
                               enforce_stationarity=False, enforce_invertibility=False)
            
            fitted = model.fit()
            forecast = fitted.forecast(steps=1)
            pred_value = max(0, forecast.iloc[0])
            predictions.append(pred_value)
            
            history = pd.concat([history, pd.Series([y_test.iloc[t]], index=[y_test.index[t]])])
            
        except Exception as e:
            predictions.append(history.mean())
    
    predictions = pd.Series(predictions, index=test_idx)
    
    mae = mean_absolute_error(y_test, predictions)
    rmse = np.sqrt(mean_squared_error(y_test, predictions))
    
    return predictions, mae, rmse

# Store results
model_results = []
```

---

## AR Models

### Autoregressive Model: AR(p)

$$y_t = c + \phi_1 y_{t-1} + \phi_2 y_{t-2} + \cdots + \phi_p y_{t-p} + \varepsilon_t$$

Equivalent to ARIMA($p$, 0, 0)

```{python}
#| code-fold: true
#| code-summary: "Show AR model fitting"

ar_orders = [(1, 0, 0), (2, 0, 0), (3, 0, 0)]

print("Fitting AR models with rolling forecast...")
for p, d, q in ar_orders:
    name = f"AR({p})"
    preds, mae, rmse = rolling_forecast_evaluation(ts, order=(p, d, q), model_name=name)
    model_results.append({
        "Model": name, "Order": (p, d, q), "Seasonal Order": None,
        "MAE": round(mae, 2), "RMSE": round(rmse, 2), "Predictions": preds
    })
    print(f"  {name}: RMSE={rmse:.2f}, MAE={mae:.2f}")
```

---

## MA Models

### Moving Average Model: MA(q)

$$y_t = \mu + \varepsilon_t + \theta_1 \varepsilon_{t-1} + \theta_2 \varepsilon_{t-2} + \cdots + \theta_q \varepsilon_{t-q}$$

Equivalent to ARIMA(0, 0, $q$)

```{python}
#| code-fold: true
#| code-summary: "Show MA model fitting"

ma_orders = [(0, 0, 1), (0, 0, 2), (0, 0, 3)]

print("Fitting MA models with rolling forecast...")
for p, d, q in ma_orders:
    name = f"MA({q})"
    preds, mae, rmse = rolling_forecast_evaluation(ts, order=(p, d, q), model_name=name)
    model_results.append({
        "Model": name, "Order": (p, d, q), "Seasonal Order": None,
        "MAE": round(mae, 2), "RMSE": round(rmse, 2), "Predictions": preds
    })
    print(f"  {name}: RMSE={rmse:.2f}, MAE={mae:.2f}")
```

---

## ARMA Models

### ARMA(p, q) Model

$$y_t = c + \phi_1 y_{t-1} + \cdots + \phi_p y_{t-p} + \varepsilon_t + \theta_1 \varepsilon_{t-1} + \cdots + \theta_q \varepsilon_{t-q}$$

```{python}
#| code-fold: true
#| code-summary: "Show ARMA model fitting"

arma_orders = [(1, 0, 1), (2, 0, 1), (1, 0, 2), (2, 0, 2)]

print("Fitting ARMA models with rolling forecast...")
for p, d, q in arma_orders:
    name = f"ARMA({p},{q})"
    preds, mae, rmse = rolling_forecast_evaluation(ts, order=(p, d, q), model_name=name)
    model_results.append({
        "Model": name, "Order": (p, d, q), "Seasonal Order": None,
        "MAE": round(mae, 2), "RMSE": round(rmse, 2), "Predictions": preds
    })
    print(f"  {name}: RMSE={rmse:.2f}, MAE={mae:.2f}")
```

---

## ARIMA Models

### ARIMA(p, d, q) Model

$$(1 - \phi_1 B - \cdots - \phi_p B^p)(1 - B)^d y_t = (1 + \theta_1 B + \cdots + \theta_q B^q)\varepsilon_t$$

where $B$ is the backshift operator and $d$ is the differencing order.

```{python}
#| code-fold: true
#| code-summary: "Show ARIMA model fitting"

arima_orders = [(1, 0, 1), (2, 0, 1), (1, 1, 1), (2, 1, 1), (1, 0, 2)]

print("Fitting ARIMA models with rolling forecast...")
for p, d, q in arima_orders:
    name = f"ARIMA({p},{d},{q})"
    preds, mae, rmse = rolling_forecast_evaluation(ts, order=(p, d, q), model_name=name)
    model_results.append({
        "Model": name, "Order": (p, d, q), "Seasonal Order": None,
        "MAE": round(mae, 2), "RMSE": round(rmse, 2), "Predictions": preds
    })
    print(f"  {name}: RMSE={rmse:.2f}, MAE={mae:.2f}")
```

---

## SARIMA Models

### Seasonal ARIMA: SARIMA(p,d,q)(P,D,Q)[s]

$$\Phi_P(B^s) \phi_p(B) \nabla_s^D \nabla^d y_t = \Theta_Q(B^s) \theta_q(B) \varepsilon_t$$

where:
- $(p,d,q)$ = Non-seasonal order
- $(P,D,Q,s)$ = Seasonal order
- $s = 12$ (monthly seasonality)

```{python}
#| code-fold: true
#| code-summary: "Show SARIMA model fitting"

sarima_specs = [
    ((1, 0, 1), (1, 1, 1, 12)),
    ((2, 0, 1), (1, 1, 1, 12)),
    ((1, 1, 1), (1, 1, 1, 12)),
    ((0, 0, 1), (1, 1, 1, 12)),
    ((1, 0, 0), (1, 1, 0, 12)),
]

print("Fitting SARIMA models with rolling forecast...")
for order, seasonal in sarima_specs:
    p, d, q = order
    P, D, Q, s = seasonal
    name = f"SARIMA({p},{d},{q})({P},{D},{Q})[{s}]"
    preds, mae, rmse = rolling_forecast_evaluation(ts, order=order, seasonal_order=seasonal, model_name=name)
    model_results.append({
        "Model": name, "Order": order, "Seasonal Order": seasonal,
        "MAE": round(mae, 2), "RMSE": round(rmse, 2), "Predictions": preds
    })
    print(f"  {name}: RMSE={rmse:.2f}, MAE={mae:.2f}")

print("\n✓ All models fitted successfully")
```

---

## Model Comparison

### Evaluation Metrics

**Mean Absolute Error (MAE):**
$$\text{MAE} = \frac{1}{n} \sum_{t=1}^{n} |y_t - \hat{y}_t|$$

**Root Mean Squared Error (RMSE):**
$$\text{RMSE} = \sqrt{\frac{1}{n} \sum_{t=1}^{n} (y_t - \hat{y}_t)^2}$$

```{python}
#| code-fold: true
#| code-summary: "Show comparison table"

# Create comparison dataframe
results_df = pd.DataFrame([{k: v for k, v in r.items() if k != "Predictions"} 
                           for r in model_results])
results_df = results_df.sort_values("RMSE").reset_index(drop=True)
results_df["Rank"] = range(1, len(results_df) + 1)
results_df[["Rank", "Model", "RMSE", "MAE"]]
```

```{python}
#| code-fold: true
#| code-summary: "Show comparison chart"

fig = px.bar(
    results_df.head(10).sort_values("RMSE"),
    x="Model",
    y="RMSE",
    color="RMSE",
    color_continuous_scale="RdYlGn_r",
    title="Top 10 Models by RMSE (Lower is Better)"
)
fig.update_layout(template="plotly_white", height=400)
fig.show()
```

---

## Best Model Selection

```{python}
#| code-fold: true
#| code-summary: "Show best model"

best_idx = results_df["RMSE"].idxmin()
best = results_df.loc[best_idx]
best_preds = model_results[best_idx]["Predictions"]

print(f"✓ Best Model: {best['Model']}")
print(f"  Order: {best['Order']}")
print(f"  Seasonal Order: {best['Seasonal Order']}")
print(f"  RMSE: {best['RMSE']:.2f}")
print(f"  MAE: {best['MAE']:.2f}")
```

::: {.columns}
::: {.column width="50%"}
### Why This Model?
- **Lowest RMSE** on 5-year out-of-sample test
- Rolling forecast evaluation prevents data leakage
- Captures seasonal patterns effectively
:::

::: {.column width="50%"}
::: {.callout-tip}
### Best Model Performance
- Best model selected by RMSE
- Evaluated using rolling one-step-ahead forecasts
- No information leakage from future data
:::
:::
:::

---

## Forecast vs Actual (Test Set)

```{python}
#| code-fold: true
#| code-summary: "Show forecast comparison"

train_recent = train.iloc[-120:]  # Last 10 years of training

fig = go.Figure()

fig.add_trace(go.Scatter(x=train_recent.index, y=train_recent.values, mode="lines",
                         name="Training Data", line=dict(color="#3498db", width=1.5)))

fig.add_trace(go.Scatter(x=test.index, y=test.values, mode="lines+markers",
                         name="Actual (Test)", line=dict(color="#2c3e50", width=2),
                         marker=dict(size=4)))

fig.add_trace(go.Scatter(x=best_preds.index, y=best_preds.values, mode="lines",
                         name=f"{best['Model']} Forecast", 
                         line=dict(color="#e74c3c", dash="dash", width=2)))

fig.add_vline(x=test.index[0], line_dash="dot", line_color="gray")

fig.update_layout(
    title=f"Best Model: {best['Model']} – Forecast vs Actual (RMSE={best['RMSE']:.2f})",
    xaxis_title="Date",
    yaxis_title="Rainfall (mm)",
    template="plotly_white",
    height=450,
    legend=dict(yanchor="top", y=0.99, xanchor="left", x=0.01)
)
fig.show()
```

::: {.callout-note}
The model captures the seasonal pattern well through rolling one-step-ahead forecasts.
:::

---

## Residual Diagnostics

### Residual Analysis Criteria

A good model should have residuals with:
1. **Zero mean:** $\mathbb{E}[e_t] = 0$
2. **Constant variance:** $\text{Var}(e_t) = \sigma^2$ (homoscedasticity)
3. **No autocorrelation:** $\text{Cov}(e_t, e_s) = 0$ for $t \neq s$
4. **Normality:** $e_t \sim \mathcal{N}(0, \sigma^2)$

```{python}
#| code-fold: true
#| code-summary: "Show residual analysis"

# Fit best model on full train data for diagnostics
import scipy.stats as stats
from plotly.subplots import make_subplots
from statsmodels.tsa.stattools import acf
from statsmodels.tsa.statespace.sarimax import SARIMAX
from statsmodels.tsa.arima.model import ARIMA

# --- Model Fitting ---
best_order = best["Order"]
best_seasonal = best["Seasonal Order"]

# Using SARIMAX for both cases is generally safer in statsmodels, 
# but the if/else logic is fine.
if best_seasonal is None or not isinstance(best_seasonal, tuple):
    # Note: Modern statsmodels uses ARIMA for non-seasonal too
    fitted_model = ARIMA(train, order=best_order).fit()
else:
    fitted_model = SARIMAX(
        train, 
        order=best_order, 
        seasonal_order=best_seasonal,
        enforce_stationarity=False, 
        enforce_invertibility=False
    ).fit()

resid = fitted_model.resid.dropna()

# --- Diagnostic Plots ---
fig = make_subplots(
    rows=2, cols=2,
    subplot_titles=("Residuals Over Time", "Residual Distribution", 
                    "Residual ACF", "Q-Q Plot (Normal)")
)

# 1. Residuals over time
fig.add_trace(go.Scatter(
    x=resid.index, y=resid.values, mode="lines",
    line=dict(color="#3498db"), name="Residuals"
), row=1, col=1)
fig.add_hline(y=0, line_dash="dash", line_color="red", row=1, col=1)

# 2. Histogram
fig.add_trace(go.Histogram(
    x=resid.values, nbinsx=30, 
    marker_color="#2ecc71", name="Dist"
), row=1, col=2)

# 3. ACF of residuals
# We calculate 21 lags but plot 1-20 (Lag 0 is always 1)
nlags = 20
resid_acf = acf(resid, nlags=nlags)
fig.add_trace(go.Bar(
    x=list(range(1, nlags + 1)), y=resid_acf[1:], 
    marker_color="#e74c3c", name="ACF"
), row=2, col=1)

# ACF Confidence Intervals (95%)
ci_resid = 1.96 / np.sqrt(len(resid))
fig.add_hline(y=ci_resid, line_dash="dash", line_color="gray", row=2, col=1)
fig.add_hline(y=-ci_resid, line_dash="dash", line_color="gray", row=2, col=1)

# 4. Q-Q Plot (Corrected Implementation)
# probplot calculates the theoretical quantiles and the best-fit line parameters
(osm, osr), (slope, intercept, r) = stats.probplot(resid, dist="norm", plot=None)

# Scatter points (Theoretical vs Sample)
fig.add_trace(go.Scatter(
    x=osm, y=osr, mode="markers",
    marker=dict(color="#9b59b6", size=4), name="Q-Q"
), row=2, col=2)

# Regression line
line_x = np.array([osm.min(), osm.max()])
line_y = slope * line_x + intercept
fig.add_trace(go.Scatter(
    x=line_x, y=line_y, mode="lines",
    line=dict(color="red", dash="dash"), name="Normal Line"
), row=2, col=2)

# Update layout
fig.update_layout(
    height=600, 
    showlegend=False, 
    template="plotly_white",
    title_text="Residual Diagnostics",
    # Label axes for clarity
    xaxis4_title="Theoretical Quantiles",
    yaxis4_title="Sample Quantiles"
)

fig.show()
```

```{python}
from scipy import stats
statistic, p_value = stats.shapiro(resid)

print(f"Shapiro-Wilk Test Statistic: {statistic}")
print(f"P-Value: {p_value}")

alpha = 0.05

if p_value > alpha:
    print("The data is likely normally distributed (Fail to reject H0).")
else:
    print("The data is likely not normally distributed (Reject H0).")
```

---

## Ljung-Box Test

### Testing for Residual Autocorrelation

- **$H_0$:** No autocorrelation in residuals
- **$H_1$:** Autocorrelation present
- **Decision:** p-value > 0.05 → Good model (no autocorrelation)

```{python}
#| code-fold: true
#| code-summary: "Show Ljung-Box test"

lb_test = acorr_ljungbox(resid, lags=[10, 20, 30], return_df=True)
lb_test["Conclusion"] = lb_test["lb_pvalue"].apply(
    lambda p: "No autocorrelation ✓" if p > 0.05 else "Autocorrelation detected ✗"
)
lb_test["lb_pvalue"] = lb_test["lb_pvalue"].map(lambda p: f"{p:.4f}")
lb_test
```

::: {.columns}
::: {.column width="50%"}
### Interpretation
- Ljung-Box test checks for residual autocorrelation
- p-value > 0.05 indicates residuals are white noise
- Model adequacy depends on test results
:::

::: {.column width="50%"}
::: {.callout-note}
### Diagnostics Summary
✓ Residuals centered around zero  
✓ Check Ljung-Box p-values  
✓ Approximately normal distribution on residual plot but The Shapiro-Wilk test show otherwise.
:::
:::
:::

---

## Final Model Refitting

### Refit on Complete Data

```{python}
#| code-fold: true
#| code-summary: "Show final model fitting"

# Refit best model on FULL data series
print(f"Refitting best model ({best['Model']}) on complete dataset...")

if best_seasonal is None or not isinstance(best_seasonal, tuple):
    final_model = ARIMA(ts, order=best_order)
else:
    final_model = SARIMAX(ts, order=best_order, seasonal_order=best_seasonal,
                          enforce_stationarity=False, enforce_invertibility=False)

final_fitted = final_model.fit()

print(f"\n✓ Final model fitted on {len(ts)} observations")
print(f"  AIC: {final_fitted.aic:.2f}")
print(f"  BIC: {final_fitted.bic:.2f}")
```

::: {.callout-note}
The final model is refitted on the **complete dataset** (1981–2026) to utilize all available information for forecasting.
:::

---

## 24-Month Forecast

### Forecast Generation

**h-step Ahead Forecast:**
$$\hat{y}_{T+h|T} = \mathbb{E}[y_{T+h} \mid y_1, \ldots, y_T]$$

**95% Prediction Interval:**
$$\hat{y}_{T+h|T} \pm 1.96 \sqrt{\text{Var}(e_{T+h|T})}$$

```{python}
#| code-fold: true
#| code-summary: "Show forecast generation"

# Generate 24-month forecast
forecast_horizon = 24
forecast_res = final_fitted.get_forecast(steps=forecast_horizon)
forecast_mean = forecast_res.predicted_mean.clip(lower=0)
forecast_ci = forecast_res.conf_int().clip(lower=0)

# Create forecast dates
forecast_dates = pd.date_range(
    start=ts.index[-1] + pd.DateOffset(months=1),
    periods=forecast_horizon,
    freq="MS"
)

forecast_df = pd.DataFrame({
    "Date": forecast_dates,
    "Forecast": forecast_mean.values.round(2),
    "Lower 95% CI": forecast_ci.iloc[:, 0].values.round(2),
    "Upper 95% CI": forecast_ci.iloc[:, 1].values.round(2)
})

print("24-Month Pursat Province Rainfall Forecast:")
forecast_df
```

---

## Forecast Visualization

```{python}
#| code-fold: true
#| code-summary: "Show forecast plot"

import plotly.graph_objects as go
import pandas as pd

# Ensure datetime index
ts.index = (
    ts.index.to_timestamp()
    if hasattr(ts.index, "to_timestamp")
    else ts.index
)

forecast_df["Date"] = pd.to_datetime(forecast_df["Date"])

history = ts.iloc[-120:]  # Last 10 years
forecast_start = ts.index[-1].to_pydatetime()

fig = go.Figure()

# Historical data
fig.add_trace(
    go.Scatter(
        x=history.index,
        y=history.values,
        mode="lines",
        name="Historical",
        line=dict(color="#3498db", width=1.5)
    )
)

# Forecast
fig.add_trace(
    go.Scatter(
        x=forecast_df["Date"],
        y=forecast_df["Forecast"],
        mode="lines+markers",
        name="Forecast",
        line=dict(color="#e74c3c", dash="dash", width=2),
        marker=dict(size=6)
    )
)

# Confidence interval
fig.add_trace(
    go.Scatter(
        x=pd.concat([forecast_df["Date"], forecast_df["Date"][::-1]]),
        y=pd.concat([
            forecast_df["Upper 95% CI"],
            forecast_df["Lower 95% CI"][::-1]
        ]),
        fill="toself",
        fillcolor="rgba(231, 76, 60, 0.2)",
        line=dict(color="rgba(255,255,255,0)"),
        name="95% Confidence Interval"
    )
)

# Vertical line (no annotation here)
fig.add_vline(
    x=forecast_start,
    line_dash="dot",
    line_color="gray",
    line_width=2
)

# Manual annotation (no datetime arithmetic)
fig.add_annotation(
    x=forecast_start,
    y=1,
    yref="paper",
    text="Forecast Start",
    showarrow=False,
    xanchor="left",
    yanchor="bottom",
    font=dict(size=12, color="gray")
)

fig.update_layout(
    title="Pursat Province Monthly Rainfall – 24-Month Forecast",
    xaxis_title="Date",
    yaxis_title="Rainfall (mm)",
    template="plotly_white",
    height=500,
    legend=dict(
        yanchor="top",
        y=0.99,
        xanchor="left",
        x=0.01
    )
)

fig.show()
```

---

## Forecast Interpretation

::: {.columns}
::: {.column width="50%"}
### Key Observations
- Forecast preserves **strong annual cycle**
- High rainfall predicted for monsoon months (May–October)
- Low rainfall during dry season (November–April)
- Provincial-level analysis provides localized insights
:::

::: {.column width="50%"}
### Uncertainty
::: {.callout-important}
- **Confidence intervals widen** over time
- Greater uncertainty for longer horizons
- Forecasts should be updated as new data becomes available
:::
:::
:::

---

## Annual Forecast Summary

```{python}
#| code-fold: true
#| code-summary: "Show annual summary"

forecast_df["Year"] = forecast_df["Date"].dt.year
forecast_df["Month"] = forecast_df["Date"].dt.strftime("%b")

# Pivot for display
pivot_forecast = forecast_df.pivot(index="Month", columns="Year", values="Forecast")
# Reorder months
month_order = ["Jan", "Feb", "Mar", "Apr", "May", "Jun", 
               "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"]
pivot_forecast = pivot_forecast.reindex(month_order)

fig = px.imshow(
    pivot_forecast,
    title="Pursat Province: Forecasted Monthly Rainfall Heatmap",
    labels=dict(x="Year", y="Month", color="Rainfall (mm)"),
    color_continuous_scale="Blues",
    aspect="auto"
)
fig.update_layout(height=450, template="plotly_white")
fig.show()
```

::: {.callout-note}
The heatmap shows the expected seasonal pattern: darker blues (higher rainfall) during monsoon months.
:::

---

## Model Summary Statistics

```{python}
#| code-fold: true
#| code-summary: "Show model summary"

# Extract key coefficients
summary_data = {
    "Parameter": [],
    "Estimate": [],
    "Std Error": [],
    "P-value": []
}

params = final_fitted.params
pvalues = final_fitted.pvalues
bse = final_fitted.bse

for param in params.index:
    summary_data["Parameter"].append(param)
    summary_data["Estimate"].append(round(params[param], 4))
    summary_data["Std Error"].append(round(bse[param], 4))
    summary_data["P-value"].append(round(pvalues[param], 4))

pd.DataFrame(summary_data)
```

::: {.callout-tip}
All seasonal parameters are statistically significant (p < 0.05), confirming the importance of the seasonal component.
:::

---

## Conclusions

::: {.columns}
::: {.column width="50%"}
### Key Findings
1. **Strong seasonality** dominates Pursat Province's rainfall pattern
2. **Monsoon cycle** (12-month period) is consistent over 45+ years
3. **Rolling forecast evaluation** provides unbiased model comparison
4. Best model captures seasonal patterns effectively
:::

::: {.column width="50%"}
### Methodological Highlights
::: {.callout-tip}
| Aspect | Approach |
|--------|----------|
| Data Level | Provincial (Pursat) |
| Evaluation | Rolling one-step-ahead |
| Test Period | 60 months (5 years) |
| Forecast | 24 months ahead |
:::
:::
:::

---

## Recommendations

::: {.incremental}
1. **Agricultural Planning**
   - Schedule planting/harvesting around predicted monsoon timing
   - Allocate water resources based on seasonal forecasts

2. **Disaster Preparedness**
   - Monitor deviations from forecasted rainfall
   - Prepare for potential flooding during peak monsoon months

3. **Model Improvements**
   - Incorporate climate indices (ENSO, IOD) as exogenous variables
   - Consider ensemble forecasting for better uncertainty quantification
   - Update models annually with new observations
:::

---

## Limitations

::: {.columns}
::: {.column width="50%"}
### Data Limitations
- Single province analysis (Pursat)
- Historical data quality varies over time
- Missing values required imputation
:::

::: {.column width="50%"}
### Model Limitations
- Linear ARIMA may not capture extreme events
- Long-term climate change not explicitly modeled
- Forecast uncertainty increases with horizon
:::
:::

::: {.callout-note}
Future work could explore **multi-province comparison** and **climate-informed models** (e.g., SARIMAX with ENSO indices).
:::

---

## References

::: {.columns}
::: {.column width="50%"}
### Data Source
- **HDX Cambodia Rainfall Dataset**  
  [data.humdata.org](https://data.humdata.org)
- **Province:** Pursat (PCODE with most complete data)

### Methodology
- Box, G.E.P., Jenkins, G.M., Reinsel, G.C. (2015). *Time Series Analysis: Forecasting and Control*
:::

::: {.column width="50%"}
### Tools & Libraries
- **Python:** pandas, numpy, statsmodels, scipy
- **Visualization:** Plotly
- **Presentation:** Quarto RevealJS
- **Evaluation:** Rolling one-step-ahead forecasts
:::
:::

---

## {.center}

### Thank You!

::: {.columns}
::: {.column width="100%"}
**Course:** Time Series Analysis  
**Group:** 01  
**Instructor:** Dr. SIM Tepmony  
**Date:** January 2026

**Focus:** Pursat Province Rainfall Forecasting

::: {.callout-tip}
Questions & Discussion Welcome!
:::
:::
:::
